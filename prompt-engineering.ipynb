{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering Assignment\n",
    "\n",
    "Complete the required tasks below. Feel free to make intermediate commits along the way, but when you've finished commit with a message that makes it obvious to me you're ready for me to evaluate the work. (e.g., \"Ready for Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import openai\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell creates an Open AI client. GitHub (wisely) prevents one from putting API keys in public repositories now, so I'm using an environment variable to store my API key. ChatGPT should be able to help you create an environment variable on your system. On MacOS you can edit your shell configuration file (`.zshrc` on my machine). On a windows machine you'll use the environment variable editor application. The API key will look something like this fake one: `sk-VPAJxeOHF7YLCLweC0fFT18lbkFRPP5Yux15Rs6FTfrf6Mxj`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the training data into a polars DF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_000, 3)\n",
      "┌─────────────────────────────────┬────────────────┬───────────────┐\n",
      "│ abstract                        ┆ location_label ┆ topic_label   │\n",
      "│ ---                             ┆ ---            ┆ ---           │\n",
      "│ str                             ┆ str            ┆ str           │\n",
      "╞═════════════════════════════════╪════════════════╪═══════════════╡\n",
      "│ Salt-induced deterioration of … ┆ NonUS          ┆ Conservation  │\n",
      "│ Coyote (Canis latrans Say, 182… ┆ USA            ┆ Ecology       │\n",
      "│ Over the past decade, underwat… ┆ NonUS          ┆ Technology    │\n",
      "│ The Marine Strategy Framework … ┆ NonUS          ┆ Biodiversity  │\n",
      "│ Background: The globally abund… ┆ NonUS          ┆ Ecology       │\n",
      "│ …                               ┆ …              ┆ …             │\n",
      "│ ContextMany wildlife populatio… ┆ USA            ┆ HumanWildlife │\n",
      "│ The Atlantic-Gaspesie caribou … ┆ NonUS          ┆ Ecology       │\n",
      "│ Shade coffee has shown great p… ┆ NonUS          ┆ Ecology       │\n",
      "│ Seabirds allocate different am… ┆ NonUS          ┆ Ecology       │\n",
      "│ Dryland agriculture has extens… ┆ NonUS          ┆ Ecology       │\n",
      "└─────────────────────────────────┴────────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.read_csv(\"data/training-data.txt\",separator=\"\\t\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Assignment\n",
    "\n",
    "This data set includes 1000 scientific article abstracts and two additional columns: `location_label` indicating if the article is from a US journal and `topic_label`. The topics were determined by the researcher, Madeline Damon, although this labeling is not necessarily the same as what she used in her research. \n",
    "\n",
    "We're using this data set to explore prompt engineering, the process by which we modify prompts and attempt to improve performance. In this case, we're going to see how well we can get an Open AI model to match the `topic_label` column. (It goes without saying that you don't want to pass this column into the AI model since that would be giving the game away.)\n",
    "\n",
    "Since we're just getting started this semester, I'm going to give you some code that you can adapt for the assignment.\n",
    "\n",
    "You can read a lot more about prompt engineering on the [Open AI page](https://platform.openai.com/docs/guides/prompt-engineering). Note also that using this API costs money. You can read about the pricing [here](https://openai.com/api/pricing/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt Number Zero\n",
    "\n",
    "In this section, I'm going to build out some code to help you get started. I'll pull a random selection of 100 abstracts and ask the (old) OpenAI ChatGPT 3.5 model to classify them. Then I'll measure the accuracy. I'm going to use a very basic prompt, so I'm expecting the accuracy to be really low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (100, 3)\n",
      "┌─────────────────────────────────┬────────────────┬───────────────┐\n",
      "│ abstract                        ┆ location_label ┆ topic_label   │\n",
      "│ ---                             ┆ ---            ┆ ---           │\n",
      "│ str                             ┆ str            ┆ str           │\n",
      "╞═════════════════════════════════╪════════════════╪═══════════════╡\n",
      "│ Marine mammals and diving bird… ┆ NonUS          ┆ Ecology       │\n",
      "│ Study Objectives: Raptors are … ┆ NonUS          ┆ HumanWildlife │\n",
      "│ Sharks and rays are threatened… ┆ NonUS          ┆ Conservation  │\n",
      "│ The diet and feeding behaviour… ┆ NonUS          ┆ Ecology       │\n",
      "│ Conservation planning is incre… ┆ USA            ┆ Conservation  │\n",
      "│ …                               ┆ …              ┆ …             │\n",
      "│ A new method consisting of enr… ┆ NonUS          ┆ Technology    │\n",
      "│ Rising environmental temperatu… ┆ USA            ┆ ClimateChange │\n",
      "│ A forest of the black coral An… ┆ NonUS          ┆ Conservation  │\n",
      "│ Developing techniques to quant… ┆ USA            ┆ Ecology       │\n",
      "│ Total organic carbon (TOC), to… ┆ NonUS          ┆ Ecology       │\n",
      "└─────────────────────────────────┴────────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "random.seed(20240825)         # Set seed for reproducibility\n",
    "sample_df = df.sample(n=100)\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_prompt = \"Classify the topic of this abstract in single token.\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One note: the way I'm coding this below is not the typical \"polars\" way. Polars is designed to be very efficient working with entire columns, so typically you'd call `apply` with a function that handled the calls to the Open AI API. I've done this in a loop so that you can insert break statements and see the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df.with_columns(pl.lit(\"\").alias(\"ai_label\")) \n",
    "  # This is one way to add a new column to a polars DF\n",
    "\n",
    "total_input = 0\n",
    "total_output = 0 \n",
    "\n",
    "for idx, row in enumerate(sample_df.iter_rows()) :\n",
    "  \n",
    "  prompt = starting_prompt + row[0] # abstract in first spot in tuple\n",
    "\n",
    "  # There is a lot to learn about this chat client and the information is \n",
    "  # changing all the time. The best place to get the most up to date\n",
    "  # information is the OpenAI API documentation.\n",
    "  # https://platform.openai.com/docs/overview\n",
    "  # The information I used to build this can be found on these pages: \n",
    "  # https://platform.openai.com/docs/guides/text-generation and\n",
    "  # https://platform.openai.com/docs/guides/chat-completions\n",
    "\n",
    "  completion = client.chat.completions.create(\n",
    "          model=\"gpt-3.5-turbo\", # There are many other models you can use: https://platform.openai.com/docs/models\n",
    "          messages=[\n",
    "              {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "              {\n",
    "                  \"role\": \"user\",\n",
    "                  \"content\": prompt,\n",
    "              }\n",
    "          ] # And the messages can be more complex than this.\n",
    "      )\n",
    "\n",
    "  # break # Uncomment this break statement to take a look at this \"completion\" object\n",
    "\n",
    "  # Let's keep track of token usage\n",
    "  total_input += completion.usage.prompt_tokens\n",
    "  total_output += completion.usage.completion_tokens\n",
    "\n",
    "  # Sometimes getting information out of the reply is a bit complicated.\n",
    "  ai_label = completion.choices[0].message.content.strip()\n",
    "\n",
    "  sample_df[idx, 'ai_label'] = ai_label\n",
    "\n",
    "# This took a bit longer than a minute on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 15.00%\n",
      "Total input tokens: 34837\n",
      "Total output tokens: 260\n",
      "Total tokens: 35097\n"
     ]
    }
   ],
   "source": [
    "accuracy = (sample_df[\"ai_label\"] == sample_df[\"topic_label\"]).cast(pl.Int32).sum()/sample_df.height\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(f\"Total input tokens: {total_input}\")\n",
    "print(f\"Total output tokens: {total_output}\")\n",
    "print(f\"Total tokens: {total_input + total_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my testing I got an accuracy of 15% on this first shot. Not very good!\n",
    "\n",
    "--- \n",
    "\n",
    "Now I'm going to ask you to do a series of tasks.\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Repeat the above code with `gpt-3.5-turbo` and at least three other Open AI models. (I encourage you to choose models at very different price points such as `gpt-4` and `gpt-4o-mini`. ) Answer the following questions for each model: \n",
    "\n",
    "* What was the accuracy? \n",
    "* How many tokens were used for input and output? (If you're not changing the seed and prompt these will stay the same.) \n",
    "* What is your rough estimate of the number of tokens for input and output if you had 100,000 abstracts?\n",
    "* What was the cost of your experiment? \n",
    "* What would it cost to run on 100,000 abstracts? \n",
    "\n",
    "Do these runs and record the results here in prose. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, pick a model that you feel gives an \"acceptable\" tradeoff between price and accuracy.\n",
    "\n",
    "### Task 2\n",
    "\n",
    "Incorporate some of the ideas from the the prompt engineering page of the Open AI documentation. Be methodical and scientific in your approach: \n",
    "\n",
    "1. Make a change.\n",
    "2. Select a sample of abstracts.\n",
    "3. Measure the accuracy and estimate the cost.\n",
    "\n",
    "Document your changes here in the workbook. Do at least three rounds of improvements. Let me know if you need ideas on specific improvements to make. Report on your final version just as you did in Task 1 (accuracy, costs, cost per 100K abstracts, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a code cell for you to get started. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Settle on your final version and run it on the full set of 1000 abstracts. Report your results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
